# Benford Case Study

Abhiram Gaddam, Devan Samant

In this tutorial, we will introduce Benford's Law and illustrate its applications in fraud detection with a case study using the benford_analysis package in r.

Section 1: Introduction to Benford's Law

-- Devan to add more context
What is Benford's Law?
Benford’s law (also called the first digit law) states that the leading digits in a collection of data sets are probably going to be small. For example, most numbers in a set (about 30%) will have a leading digit of 1, when the expected probability is 11.1% (one out of nine digits). This is followed by about 17.5% starting with a number 2. This is clearly an unexpected phenomenon. To put it simply, Benford’s law is a probability distribution for the likelihood of the first digit in a set of numbers (Frunza, 2015). The formula for Benford's Law is:

$P(d) = \frac{ln(1 + \frac{1}{d})}{ln10}$
where $d$ is the leading digit (a number from 1 to 9)

Below is a distribution that shows the expected occurrence of leading digits according to Benford's Law.

NOTE: Need to figure out how to render this image remotely
![Benfords Law Distribution.](/Users/abhiramgaddam21/Desktop/b1.jpeg)

A few caveats regarding the application of Benford's Law:
1) Benford's Law works better with larger sets of data. While the law has been shown to hold true for data sets containing as few as 50 to 100 numbers, most experts believe data sets of 500 or more numbers are better suited for this type of analysis.

2) To conform with the law, the data set you use must contain data in which each number 1 through 9 has an equal chance of being the leading digit. Otherwise, Benford's Law doesn't apply. For example, consider a listing of the heights of all the NBA basketball players in history. In this case, because NBA players range in height from 5 feet 3 inches (Muggsy Bogues, who played from 1987 to 2001) to 7 feet 7 inches (Manute Bol and Gheorghe Mureșan, who played during the 1980s and 1990s), there are no player heights that begin with a 1, 2, 3, 4, 8, or 9; hence those digits have no chance of being the first digit in such a listing, making Benford's Law inapplicable.

While Benford's Law is not applicable to all datasets, it is generally applicable to large sets of naturally occurring numbers with some connection like:

1) Companies’ stock market values.
2) Data found in texts.
3) Demographic data, including state and city populations.
4) Income tax data.
5) Mathematical tables, like logarithms.
6) River drainage rates.
7) Scientific data.


Applications in Fraud Detection:
One primary and practical use for Benford’s law is fraud and error detection. It is expected that a large set of numbers will follow the law, so accountants, auditors, economists and tax professionals have a benchmark for what the normal levels of any particular number in a set are. Below are some famously documented examples of Benford's Law being applied towards fraud detection:

1) In the latter half of the 1990s, an accountant named Mark Nigrini found that Benford’s law can be an effective red-flag test for fabricated tax returns; True tax data usually follows Benford’s law, whereas made-up returns do not.

2) The law was used in 2001 to study economic data from Greece, with the implication that the country may have manipulated numbers to join the European Union.

3) Ponzi schemes can be detected using the law. Unrealistic returns, such as those purported by the Maddoff scam, fall far from the expected Benford probability distribution (Frunza, 2015).



Section 2: benford.analysis package in r

The Benford Analysis (benford.analysis) package provides tools that make it easier to validate data using Benford’s Law. The main purpose of the package is to identify suspicious data that need further verification.

Documentation on the package can be found here:
https://cran.r-project.org/web/packages/benford.analysis/benford.analysis.pdf


You can install the package from CRAN by running:

```{r}
install.packages("benford.analysis")
```

The package comes with 6 real datasets from Mark Nigrini’s book Benford’s Law: Applications for Forensic Accounting, Auditing, and Fraud Detection


Section 3: Example Usage of benford.analysis
Here we will give an example using 189,470 records from the corporate payments dataset which is provided with the package.

Load the package and data
```{r}
library(benford.analysis) 
data(corporate.payment) 

df <- corporate.payment
head(df)
```

To validate the data against Benford’s law you simply use the function "benford" on the appropriate column:
```{r}
bfd <- benford(df$Amount)
bfd
```
This creates an object of class “Benford” with the results for the analysis using the first two significant digits

Lets plot the bfd and observe the trends. Note that we running this analysis using the default parameters, i.e., no.of.digits = 2. This paramter can be modified if we only want to analyze the first digit 
```{r}
plot(bfd)
```

The original data is in blue and the expected frequency according to Benford’s law is in red. 
In this example, the first plot shows that the data do have a tendency to follow Benford’s law.
There is also a clear outlier at 50.

The package also provides some helper functions to further investigate the data. For example, you can easily extract the observations with the largest discrepancies by using the "getSuspects" function.

```{r}
suspects <- getSuspects(bfd, df)
suspects
```


Section 3: Case Study

--Show how to detect fraud. For eg: price and quantity. Show the graph in this randomized data. 
Let us try an experiment to see if we can use Benford's Law to detect potential data manipulation. We'll use random data for this where we can pretend a company has data made up of prices and quantities of items that they have sold.

```{r}
library(dplyr)
library(plotly)
library(tidyverse)

price <- sample(1:10000, size = 100000, replace=TRUE)
quantity <- sample(1:100000, size = 100000, replace=TRUE)
df <- data.frame(price,quantity) %>% 
  mutate(value = price*quantity) %>% 
  mutate(digit = substr(as.character(value), 1, 1))

df_group <- df %>% group_by(digit) %>% summarise(count = n()) %>%
    mutate(count_percent = count/sum(count))

base_benford = data.frame(c(1,2,3,4,5,6,7,8,9), c(.31,.176,.125,.097,.079,.067,.058,.051,.046))
colnames(base_benford) <- c('digit','percent')

ggplot(data=df_group, aes(x=digit, y=count_percent, fill="blue")) +
  geom_bar(stat="identity", fill='lightblue') + 
  geom_point(aes(x=base_benford$digit, y=base_benford$percent))

```

The total value of this data exhibits some commonality with Benford's Law but it is not exact. We will address some limitation in the next section. For now, let us try manipulating the data to see if the patterns changes. 

--Re-run on manipulated data. Show the difference in graphs. Mainly display bar charts 

In this next piece of code, we can pretend someone has entered in additional sales "randomly" by adding in relatively smaller sales under 100k.  
```{r}

value2 <- sample(1:99999, size = 150000, replace=TRUE)
df_extra_sales <- data.frame(0,0,value2)
colnames(df_extra_sales) <- c('price','quantity','value')
df2 <- data.frame(price,quantity) %>% 
  mutate(value = price*(quantity)) %>% 
  rbind(df_extra_sales)  %>% 
  mutate(digit = substr(as.character(value), 1, 1))

df_group2 <- df2 %>% group_by(digit) %>% summarise(count = n()) %>%
    mutate(count_percent = count/sum(count))

p2 <- ggplot(data=df_group2, aes(x=digit, y=count_percent)) +
  geom_bar(stat="identity", fill='lightblue') + 
  geom_point(aes(x=base_benford$digit, y=base_benford$percent))
p2
#gridExtra::grid.arrange(p1,p2, ncol=2)

df_group_combined <- data.frame(df_group$digit,df_group$count_percent,df_group2$count_percent) 
colnames(df_group_combined) <- c('digit','original_percent','updated_percent')
df_group_combined <- df_group_combined %>% pivot_longer(cols=c('original_percent','updated_percent'))
colnames(df_group_combined) <- c('digit','dataset','count_percent')

ggplot(data=df_group_combined, aes(x=digit, y=count_percent, fill=dataset)) +
  geom_bar(stat="identity", position='dodge') 
```

```{r}

bfd_1 <- benford(df$value)
bfd_1

bfd_2 <- benford(df2$value)
bfd_2


```

--Comparison of statistics between df and df2:

Df
Statistic  Value
        Mean  0.525
         Var  0.073
 Ex.Kurtosis -1.049
    Skewness -0.142


Df2
Statistic  Value
        Mean  0.616
         Var  0.074
 Ex.Kurtosis -0.837
    Skewness -0.491


--If the data follows Benford’s Law, the numbers should be close to:
Statistic	Value
Mean	0.5
Variance	1/12 (0.08333…)
Ex. Kurtosis	-1.2
Skewness	0


--apply benford package metrics too?
We can see that the distribution has changed between graphs with this manipulation. This is an extreme example to highlight a point. Note that this does not prove anything but is just an indicator that something looks weird. History has shown that real instances are also detectable because human manipulation (even if using randomness) can be basic and many people do not realize that Benford's Law is something they need to look out for. Now a bad actor that has a stats background that knows how to properly generate fake sales would be hard to catch. 




Section 4 Conclusion: Show what we learned, its drawbacks, future readings on the package.




Sources:
Benford, F. “The Law of Anomalous Numbers,” Proceedings of the American Philosophical Society, 78, 551–572. 1938.

https://cran.r-project.org/web/packages/benford.analysis/benford.analysis.pdf

https://www.statisticshowto.com/benfords-law/

Frunza, M. (2015). Solving Modern Crime in Financial Markets: Analytics and Case Studies. Academic Press.

https://www.journalofaccountancy.com/issues/2017/apr/excel-and-benfords-law-to-detect-fraud.html#:~:text=Briefly%20explained%2C%20Benford's%20Law%20maintains,leading%20digit%20with%20decreasing%20frequency.

